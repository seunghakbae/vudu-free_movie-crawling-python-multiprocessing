{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "from multiprocessing import Process\n",
    "import multiprocessing\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from multiprocessing import Pool\n",
    "from concurrent import futures\n",
    "import concurrent\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import itertools\n",
    "import json\n",
    "\n",
    "import re\n",
    "\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "\n",
    "import pickle\n",
    "from fake_useragent import UserAgent\n",
    "\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perf_clock(func):\n",
    "    \n",
    "    \"\"\"\n",
    "    calculate total time taken\n",
    "    \n",
    "    params : func\n",
    "    \n",
    "    return : wrapper\n",
    "    \"\"\"\n",
    "    \n",
    "    def wrapper(*args, **kwargs):\n",
    "        \n",
    "        #start\n",
    "        st = time.perf_counter()\n",
    "        \n",
    "        result = func(*args, **kwargs)\n",
    "        \n",
    "        et = time.perf_counter() - st\n",
    "        \n",
    "        # name of function\n",
    "        name = func.__name__\n",
    "\n",
    "        print('site name : %s \\ntotal time : [%0.5fs]' % (name, et))\n",
    "\n",
    "        return result\n",
    "\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_number_tag():\n",
    "\n",
    "    \"\"\"\n",
    "    Crawls total number of free streaming movies specified at vudu site using selenium.\n",
    "    Needs to divide total number by 50 because json file provides 50 movies every iteration and saves it in crawl_turn_number\n",
    "    \n",
    "    outputs : crawl_turn_number(int)\n",
    "    \"\"\"\n",
    "    \n",
    "    global chrome_driver_path\n",
    "    \n",
    "    options = Options()\n",
    "    options.add_argument('--headless')\n",
    "    \n",
    "    with webdriver.Chrome(chrome_driver_path,chrome_options=options) as driver:\n",
    "\n",
    "        driver.implicitly_wait(3)\n",
    "\n",
    "        driver.get('https://www.vudu.com/content/movies/uxrow/Movies/88')\n",
    "\n",
    "        time.sleep(5)\n",
    "\n",
    "        # get total number tag\n",
    "        total_number_tag = WebDriverWait(driver, 30).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"reactApp\"]/div/div/div/div[2]/div/span/h1'))).text\n",
    "\n",
    "        # preprocess\n",
    "        total_number = int(total_number_tag.split(' ')[-1].replace(\"(\", \"\").replace(\")\", \"\"))\n",
    "\n",
    "        # get the number of total crawling number\n",
    "        # receives 50 movies at each iteration, so divide by 50.\n",
    "        crawl_turn_num = total_number // 50\n",
    "\n",
    "    return crawl_turn_num + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawling(crawl_list):\n",
    "    \n",
    "    \"\"\"\n",
    "    Crawls vudu_id and title from json file. Creates url and crawls title, poster url using selenium. Checks if crawled title and title from json file matches. \n",
    "    Crawls overview, genre, runtime, release date, country and director Using another api.\n",
    "    Append all cralwed data to rows and return rows.\n",
    "    \n",
    "    if title does not match, it prints title and url.\n",
    "    \n",
    "    if url does not open, it prints url.\n",
    "    \n",
    "    input : crawl_list(range)\n",
    "    \n",
    "    output : rows(list)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    global chrome_driver_path\n",
    "\n",
    "    options = Options()\n",
    "    options.add_argument('--headless')\n",
    "    options.add_argument('--no-sandbox')\n",
    "\n",
    "    # row list to save \n",
    "    rows = []\n",
    "\n",
    "    print('crawling starts')\n",
    "        \n",
    "    for i in tqdm(crawl_list):\n",
    "\n",
    "        offset_num = i * 50\n",
    "\n",
    "        url = 'https://apicache.vudu.com/api2/?_type=uxElementSearch&contentEncoding=gzip&count=50&format=application%2Fjson&offset={}&sortBy=streamScore&uxRowId=88'.format(offset_num)\n",
    "        \n",
    "        session = requests.Session()\n",
    "\n",
    "        session.trust_env = False  # Don't read proxy settings from OS\n",
    "\n",
    "        req = session.get(url).text\n",
    "\n",
    "        session.trust_env = True\n",
    "\n",
    "        session.close()\n",
    "\n",
    "        json_list = (json.loads(req.replace('/*-secure-', '').replace('*/', '')))['uxElement']\n",
    "        \n",
    "        options = Options()\n",
    "        options.add_argument('--headless')\n",
    "        options.add_argument('--no-sandbox')\n",
    "        \n",
    "        driver = webdriver.Chrome(chrome_driver_path, options=options)\n",
    "        \n",
    "        for j, movie in enumerate(json_list):\n",
    "\n",
    "            vudu_id, title, release, genre, director, actor, country, runtime, production, overview, url, poster_url = [None for _ in range(12)]\n",
    "\n",
    "            # vudu_id\n",
    "            try:\n",
    "                vudu_id = movie['assetId'][0]\n",
    "            except Exception as e:\n",
    "                # print(e)\n",
    "                vudu_id = None\n",
    "\n",
    "            # title\n",
    "            try:\n",
    "                title = movie['label'][0]\n",
    "            except Exception as e:\n",
    "                # print(e)\n",
    "                title = None\n",
    "\n",
    "\n",
    "            # url\n",
    "            try:\n",
    "                characters_to_remove = \"!()@:,.?\"\n",
    "                pattern = \"[\" + characters_to_remove + \"]\"\n",
    "                url_title = re.sub(pattern, \"\", title).replace(\" \", \"-\")\n",
    "\n",
    "                url_save = 'https://www.vudu.com/content/movies/details/' + url_title + '/' + vudu_id\n",
    "\n",
    "            except Exception as e:\n",
    "                url_save = None\n",
    "            \n",
    "            # check whether url is valid\n",
    "            driver.get(url_save)\n",
    "            \n",
    "            try:\n",
    "                title_crawled = WebDriverWait(driver, 480).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"reactApp\"]/div/div/div/div[2]/div[1]/div[1]/div[2]/div/div/div[2]/div[1]/div/div/div'))).text\n",
    "                \n",
    "                # if title_Crawled from movie page and title got from json data are different, \n",
    "                # url is wrong\n",
    "                if title_crawled != title:\n",
    "                    print('title_crawled :', title_crawled)\n",
    "                    print('title : ', title)\n",
    "                    raise Exception\n",
    "                \n",
    "                # crawl poster url\n",
    "                try:\n",
    "                    poster_url = WebDriverWait(driver, 300).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"reactApp\"]/div/div/div/div[2]/div[1]/div[1]/div[2]/div/div/div[1]/span/div[1]/span/div[2]/img'))).get_attribute('src')\n",
    "\n",
    "                except Exception as e:\n",
    "                    # print(e)\n",
    "                    poster_url = None\n",
    "                \n",
    "                if vudu_id:\n",
    "                    \n",
    "                    session = requests.Session()\n",
    "                    \n",
    "                    session.trust_env = False  # Don't read proxy settings from OS\n",
    "                    \n",
    "                    url = 'https://apicache.vudu.com/api2/?_type=contentSearch&contentEncoding=gzip&contentId={}&dimensionality=any&followup=ultraVioletability&followup=longCredits&followup=usefulTvPreviousAndNext&followup=superType&followup=episodeNumberInSeason&followup=advertContentDefinitions&followup=tag&followup=hasBonusWithTagExtras&followup=subtitleTrack&followup=ratingsSummaries&followup=geneGenres&followup=seasonNumber&followup=trailerEditionId&followup=genres&followup=usefulStreamableOffers&followup=walmartOffers&followup=preOrderOffers&followup=editions&followup=merchandiseContentMaps&followup=ageLimit&followup=parentalGuide&followup=hasClearplay&followup=promoTags&followup=advertEnabled&followup=uxPromoTags&format=application%2Fjson'.format(vudu_id)\n",
    "                    \n",
    "                    req = session.get(url).text\n",
    "\n",
    "                    session.trust_env = True\n",
    "\n",
    "                    session.close()\n",
    "\n",
    "                    json_req1 = json.loads(req.replace('/*-secure-', '').replace('*/', ''))\n",
    "                    \n",
    "                    # get overview\n",
    "                    try:\n",
    "                        overview = json_req1['content'][0]['description'][0] \n",
    "                    except Exception as e:\n",
    "                        # print(e)\n",
    "                        overview = None\n",
    "\n",
    "                    # get genre\n",
    "                    try:\n",
    "                        genres = json_req1['content'][0]['genres'][0]['genre']\n",
    "\n",
    "                        genres_ = \"\"\n",
    "\n",
    "                        for i, genre in enumerate(genres):\n",
    "                            if i == 0:\n",
    "                                genres_ += genre['name'][0]\n",
    "                            else:\n",
    "                                genres_ += \",\" + genre['name'][0]\n",
    "                    except Exception as e:\n",
    "                        # print(e)\n",
    "                        genres_ = None\n",
    "\n",
    "                    # get runtime\n",
    "                    try:\n",
    "                        runtime = int(json_req1['content'][0]['lengthSeconds'][0]) // 60\n",
    "                    except Exception as e:\n",
    "                        # print(e)\n",
    "                        runtime = None\n",
    "\n",
    "                    # get release\n",
    "                    try:\n",
    "                        release = json_req1['content'][0]['releaseTime'][0].replace('-', '.')\n",
    "                    except Exception as e:\n",
    "                        # print(e)\n",
    "                        release = None\n",
    "\n",
    "                    # get country\n",
    "                    try:\n",
    "                        country = json_req1['content'][0]['country'][0]\n",
    "                    except Exception as e:\n",
    "                        # print(e)\n",
    "                        country = None\n",
    "\n",
    "                    # get director\n",
    "                    try:\n",
    "                        credits_list = json_req1['content'][0]['credits'][0]['credit']\n",
    "\n",
    "                        for credits in credits_list:\n",
    "\n",
    "                            role = credits['role']\n",
    "                            if 'Director' in role:\n",
    "                                director = credits['firstName'][0] + \" \" + credits['lastName'][0]\n",
    "                    except Exception as e:\n",
    "                        # print(e)\n",
    "                        director = None\n",
    "\n",
    "                    rows.append([vudu_id, title, release, genres_, director, None, country, runtime, None, overview, url_save, poster_url])\n",
    "                    \n",
    "            except Exception as e:\n",
    "                # print(e)\n",
    "                print('url does not open : ', title, url_save)\n",
    "                continue  \n",
    "            \n",
    "        driver.close()\n",
    "        \n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@perf_clock\n",
    "def crawl_vudu(output_path):\n",
    "    \n",
    "    global chrome_driver_path\n",
    "    \n",
    "    \"\"\"\n",
    "    Get crawl_turn_number from get_total_number_tag() and split it into cpu_count. Each process will crawl splited number of movies using crawling method.\n",
    "    \n",
    "    Creates excel file and saves at output_path.\n",
    "    \n",
    "    input : output_path(str) -> excel path.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # get total number of movies\n",
    "    total_number_tags = get_total_number_tag()\n",
    "    # total_number_tags = multiprocessing.cpu_count()\n",
    "    # split total number of tags into equal number \n",
    "    \n",
    "    cpu_count = multiprocessing.cpu_count()\n",
    "    print(\"cpu_count : %d\" % (cpu_count))\n",
    "    \n",
    "    # split total number of movies into fractions\n",
    "    total_number_tags_list = [list(array) for array in np.array_split(range(total_number_tags), cpu_count)]\n",
    "    \n",
    "    # use multiprocessing\n",
    "    with concurrent.futures.ProcessPoolExecutor(max_workers= cpu_count) as executor:\n",
    "        \n",
    "        tests = executor.map(crawling, total_number_tags_list)\n",
    "    \n",
    "    # create dataframe\n",
    "    vudu_df = pd.DataFrame(columns = ['vudu_id', 'title', 'release', 'genre','director', 'actor', 'country', 'runtime', 'production', 'overview','url', 'image_url'])\n",
    "    \n",
    "    print('saving dataframe...')\n",
    "    \n",
    "    tests_list = list(tests)\n",
    "    \n",
    "    count = 0\n",
    "\n",
    "    for i in tqdm(tests_list):\n",
    "        for j in i:\n",
    "            vudu_df.loc[count] = j\n",
    "            count += 1\n",
    "    \n",
    "    return vudu_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def google_search(movie):\n",
    "    \n",
    "    title = movie[\"title\"]\n",
    "    director = movie[\"director\"]\n",
    "    \n",
    "    # userAgent 만들기.\n",
    "    ua = UserAgent(verify_ssl=False)\n",
    "    userAgent = {'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/68.0.3440.106 Safari/537.36'}\n",
    "    options = Options()\n",
    "    options.add_argument(f'user-agent={userAgent}')\n",
    "\n",
    "    driver = webdriver.Chrome('/Users/mycelebs-it01/Desktop/chromedriver' , chrome_options=options)\n",
    "\n",
    "    driver.get(\"http://www.google.com\")\n",
    "    \n",
    "    # cookies 불러오기\n",
    "#     cookies = pickle.load(open(\"cookies.pkl\", \"rb\"))\n",
    "#     for cookie in cookies:\n",
    "#         driver.add_cookie(cookie)\n",
    "    \n",
    "    \n",
    "    search_list = []\n",
    "    for i in range(len(title)):\n",
    "        try:\n",
    "            search_list.append(title[i]+\" \"+director[i])\n",
    "        except:\n",
    "            search_list.append(title[i])\n",
    "\n",
    "    release = []; release_list = []\n",
    "\n",
    "    time.sleep(5)\n",
    "\n",
    "    for i in tqdm(range((len(movie)))):\n",
    "        url = 'https://www.google.com/search?q='+search_list[i]\n",
    "        driver.get(url)\n",
    "        time.sleep(7)\n",
    "        try:\n",
    "            soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "            if soup.find(\"span\",class_ = \"w8qArf\").text.strip() == \"개봉일:\":\n",
    "                year = soup.find(\"span\",class_ = \"LrzXr kno-fv\").text\n",
    "                release.append(year)\n",
    "                print(year)\n",
    "                time.sleep(3)\n",
    "            else:\n",
    "                release.append(None)\n",
    "                print(None)\n",
    "        except Exception as error:\n",
    "            release.append(None)\n",
    "            print(None)\n",
    "\n",
    "    driver.close()\n",
    "    \n",
    "    for release_one in release:\n",
    "        print(release_one)\n",
    "        try:\n",
    "            if \"일\" in release_one:\n",
    "                tmp = release_one.split(\" \")\n",
    "                tmp = (tmp[0]+tmp[1]+tmp[2]).replace(\"년\",\".\").replace(\"월\",\".\").replace(\"일\",\"\")\n",
    "                release_list.append(tmp)\n",
    "                print(\"final: \",tmp)\n",
    "            elif \"월\" in release_one:\n",
    "                release_list.append(None)\n",
    "                print(\"final: \",None)\n",
    "            elif \"년\" in release_one:\n",
    "                release_list.append(None)\n",
    "                print(\"final: \",None)\n",
    "            else:\n",
    "                release_list.append(None)\n",
    "                print(\"final: \",None)\n",
    "        except:\n",
    "            release_list.append(None)\n",
    "            print(\"final: \",None)\n",
    "    \n",
    "    print(len(release_list))\n",
    "    \n",
    "    movie['release'] = release_list\n",
    "    \n",
    "    with pd.ExcelWriter(output_path, engine='xlsxwriter', options={'strings_to_urls' : False}) as writer:\n",
    "        movie.to_excel(writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:15: DeprecationWarning: use options instead of chrome_options\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu_count : 8\n",
      "crawling starts\n",
      "crawling starts\n",
      "crawling starts\n",
      "crawling starts\n",
      "crawling starts\n",
      "crawling starts\n",
      "crawling starts\n",
      "crawling starts\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ebe9034929a4e0c81da231ab238788d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=14.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4a34b276ffa40fd9deb665807c866ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=14.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5fea431d93d47159d727919a2b127de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=14.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f755092aa7c543f58bbd2cf5209c8aea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=14.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9bea3abc0e94dee8c2f2eac91322c1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=14.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d525ba55a9d4459b5d8ddd8dfbbe8d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=13.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b90934cd5b7470bbd42beb9ce60ada7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=13.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a75b2515dfde40208e610c1712003631",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=13.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title_crawled : Meshuggah: Alive \n",
      "title :  Meshuggah: Alive \n",
      "url does not open :  Meshuggah: Alive  https://www.vudu.com/content/movies/details/Meshuggah-Alive /277635\n",
      "title_crawled : Toto: 35th Anniversary Tour - Live in Poland\n",
      "title :  Toto: 35th Anniversary Tour - Live in Poland\n",
      "url does not open :  Toto: 35th Anniversary Tour - Live in Poland https://www.vudu.com/content/movies/details/Toto-35th Anniversary-Tour---Live-in-Poland/1050436\n",
      "title_crawled : Classic Albums: Motörhead's Ace of Spades\n",
      "title :  Classic Albums: MotÃ¶rhead's Ace of Spades\n",
      "url does not open :  Classic Albums: MotÃ¶rhead's Ace of Spades https://www.vudu.com/content/movies/details/Classic-Albums-MotÃ¶rhead's-Ace-of-Spades/1049949\n",
      "title_crawled : Yes: Songs From Tsongas - 35th Anniversary Concert\n",
      "title :  Yes: Songs From Tsongas - 35thÂ Anniversary Concert\n",
      "url does not open :  Yes: Songs From Tsongas - 35thÂ Anniversary Concert https://www.vudu.com/content/movies/details/Yes-Songs-From-Tsongas---35thÂ Anniversary-Concert/1050442\n",
      "title_crawled : La Noche Del Ratón\n",
      "title :  La Noche Del RatÃ³n\n",
      "url does not open :  La Noche Del RatÃ³n https://www.vudu.com/content/movies/details/La-Noche-Del-RatÃ³n/1200256\n",
      "url does not open :  Harlequin #7: This Matter Of Marriage (Spanish Dubbed) https://www.vudu.com/content/movies/details/Harlequin-#7-This-Matter-Of-Marriage-Spanish-Dubbed/1328680\n",
      "url does not open :  F/X https://www.vudu.com/content/movies/details/F/X/140747\n",
      "title_crawled : Britain's Royals: The House of Windsor\n",
      "title :  Britain's Royals:  The House of Windsor\n",
      "url does not open :  Britain's Royals:  The House of Windsor https://www.vudu.com/content/movies/details/Britain's-Royals--The-House-of-Windsor/1034495\n",
      "url does not open :  Harlequin #1: A Change Of Place (Spanish Dubbed) https://www.vudu.com/content/movies/details/Harlequin-#1-A-Change-Of-Place-Spanish-Dubbed/1328666\n",
      "title_crawled : Country's Family Reunion - a Grand Ole Time: Volume Four\n",
      "title :  Country's Family Reunion  -  a Grand Ole Time: Volume Four\n",
      "url does not open :  Country's Family Reunion  -  a Grand Ole Time: Volume Four https://www.vudu.com/content/movies/details/Country's-Family-Reunion-----a-Grand-Ole-Time-Volume-Four/813104\n",
      "url does not open :  Harlequin #2: Another Woman (Spanish Dubbed) https://www.vudu.com/content/movies/details/Harlequin-#2-Another-Woman-Spanish-Dubbed/1328672\n",
      "title_crawled : Süskind\n",
      "title :  SÃ¼skind\n",
      "url does not open :  SÃ¼skind https://www.vudu.com/content/movies/details/SÃ¼skind/970239\n",
      "url does not open :  Classic Albums: John Lennon and the Plastic Ono Band's John Lennon/Plastic Ono Band https://www.vudu.com/content/movies/details/Classic-Albums-John-Lennon-and-the-Plastic-Ono-Band's-John-Lennon/Plastic-Ono-Band/1049934\n",
      "url does not open :  Nick Cannon: F#ck Nick Cannon https://www.vudu.com/content/movies/details/Nick-Cannon-F#ck-Nick-Cannon/874803\n",
      "url does not open :  F/X 2 https://www.vudu.com/content/movies/details/F/X-2/140748\n",
      "url does not open :  Harlequin #9: Diamond Girl (Spanish Dubbed) https://www.vudu.com/content/movies/details/Harlequin-#9-Diamond-Girl-Spanish-Dubbed/1328682\n",
      "url does not open :  #Artoffline https://www.vudu.com/content/movies/details/#Artoffline/993225\n",
      "url does not open :  Harlequin #3: Treacherous Beauties (Spanish Dubbed) https://www.vudu.com/content/movies/details/Harlequin-#3-Treacherous-Beauties-Spanish-Dubbed/1328674\n",
      "title_crawled : La Copa de los Sueños\n",
      "title :  La Copa de los SueÃ±os\n",
      "url does not open :  La Copa de los SueÃ±os https://www.vudu.com/content/movies/details/La-Copa-de-los-SueÃ±os/882348\n",
      "title_crawled : Country's Family Reunion - a Grand Ole Time: Volume Three\n",
      "title :  Country's Family Reunion  -  a Grand Ole Time: Volume Three\n",
      "url does not open :  Country's Family Reunion  -  a Grand Ole Time: Volume Three https://www.vudu.com/content/movies/details/Country's-Family-Reunion-----a-Grand-Ole-Time-Volume-Three/813112\n",
      "url does not open :  #Love Swag https://www.vudu.com/content/movies/details/#Love-Swag/817378\n",
      "url does not open :  Who the #$& % is Jackson Pollock? https://www.vudu.com/content/movies/details/Who-the-#$&-%-is-Jackson-Pollock/128192\n",
      "url does not open :  CSNY / Deja Vu https://www.vudu.com/content/movies/details/CSNY-/-Deja-Vu/138942\n",
      "url does not open :  Harlequin #5: At The Midnight Hour (Spanish Dubbed) https://www.vudu.com/content/movies/details/Harlequin-#5-At-The-Midnight-Hour-Spanish-Dubbed/1328676\n",
      "\n",
      "url does not open :  110% https://www.vudu.com/content/movies/details/110%/491545\n",
      "url does not open :  Harlequin #6: The Awakening (Spanish Dubbed) https://www.vudu.com/content/movies/details/Harlequin-#6-The-Awakening-Spanish-Dubbed/1328678\n",
      "title_crawled : Noëlle\n",
      "title :  NoÃ«lle\n",
      "url does not open :  NoÃ«lle https://www.vudu.com/content/movies/details/NoÃ«lle/1200244\n",
      "url does not open :  V/H/S: Viral https://www.vudu.com/content/movies/details/V/H/S-Viral/569809\n",
      "\n",
      "url does not open :  Jarabe de Palo: Tour Americano 14/15 https://www.vudu.com/content/movies/details/Jarabe-de-Palo-Tour-Americano-14/15/812008\n",
      "url does not open :  AC/DC: Dirty Deeds https://www.vudu.com/content/movies/details/AC/DC-Dirty-Deeds/470691\n",
      "url does not open :  Harlequin #12: Recipe For Revenge (Spanish Dubbed) https://www.vudu.com/content/movies/details/Harlequin-#12-Recipe-For-Revenge-Spanish-Dubbed/1328670\n",
      "url does not open :  11/11/11 https://www.vudu.com/content/movies/details/11/11/11/241723\n",
      "title_crawled : Country's Family Reunion - a Grand Ole Time: Volume One\n",
      "title :  Country's Family Reunion  -  a Grand Ole Time: Volume One\n",
      "url does not open :  Country's Family Reunion  -  a Grand Ole Time: Volume One https://www.vudu.com/content/movies/details/Country's-Family-Reunion-----a-Grand-Ole-Time-Volume-One/813108\n",
      "url does not open :  #Captured https://www.vudu.com/content/movies/details/#Captured/892488\n",
      "\n",
      "url does not open :  The Last Secrets of 9/11 https://www.vudu.com/content/movies/details/The-Last-Secrets-of-9/11/1306849\n",
      "url does not open :  Story/Time https://www.vudu.com/content/movies/details/Story/Time/812960\n",
      "\n",
      "url does not open :  DC 9/11: Time of Crisis https://www.vudu.com/content/movies/details/DC-9/11-Time-of-Crisis/1272259\n",
      "url does not open :  7 Days in September: A Powerful Story About 9/11 https://www.vudu.com/content/movies/details/7-Days-in-September-A-Powerful-Story-About-9/11/42597\n",
      "\n",
      "\n",
      "\n",
      "url does not open :  Harlequin #11: Loving Evangeline (Spanish Dubbed) https://www.vudu.com/content/movies/details/Harlequin-#11-Loving-Evangeline-Spanish-Dubbed/1328668\n",
      "title_crawled : Can't Stand Losing You: Surviving the Police\n",
      "title :  Can't Stand Losing You:  Surviving the Police\n",
      "url does not open :  Can't Stand Losing You:  Surviving the Police https://www.vudu.com/content/movies/details/Can't-Stand-Losing-You--Surviving-the-Police/1050542\n",
      "\n",
      "saving dataframe...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1a025cfe41a4362915aacaed84d936f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "site name : crawl_vudu \n",
      "total time : [4576.97785s]\n"
     ]
    }
   ],
   "source": [
    "chrome_driver_path = '/Users/mycelebs-it01/Desktop/chromedriver'\n",
    "output_path = './crawl_vudu.xlsx'\n",
    "\n",
    "vudu_df = crawl_vudu(output_path)\n",
    "\n",
    "google_search(vudu_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
